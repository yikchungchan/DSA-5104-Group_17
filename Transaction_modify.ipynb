{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries:\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import timedelta, datetime\n",
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"review\": \"generated data/review_data.json\",\n",
    "    \"meta\": \"generated data/meta_data.json\",\n",
    "    \"user\": \"generated data/user_data.json\"\n",
    "}\n",
    "\n",
    "# Load each JSON file using json.load() and convert directly to pandas DataFrame\n",
    "review_df = pd.read_json(file_paths[\"review\"], lines=True, encoding='utf-8')\n",
    "meta_df = pd.read_json(file_paths[\"meta\"], lines=True, encoding='utf-8')\n",
    "user_df = pd.read_json(file_paths[\"user\"], lines=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6460965, 11)\n",
      "(1210967, 18)\n",
      "(658400, 8)\n",
      "overall                                                           4\n",
      "vote                                                              1\n",
      "verified                                                      False\n",
      "reviewTime                                              08 14, 2000\n",
      "unixReviewTime                                            966211200\n",
      "reviewerID                                           A19646YDU8IH1I\n",
      "reviewerName                                    Robert Ian Farquhar\n",
      "asin                                                     B00000DMA8\n",
      "style                                     {'Edition:': ' Standard'}\n",
      "reviewText        Okay I admit it, the two main reasons I bought...\n",
      "summary                                                   Good Fun!\n",
      "Name: 945, dtype: object\n",
      "asin                                                      B00001XDVT\n",
      "title                                  Armorines: Project S.W.A.R.M.\n",
      "feature            [Great Condition, cleaned and tested, *Cartrid...\n",
      "description        [Alien bugs have swarmed to earth with a nasty...\n",
      "price                                                         $19.90\n",
      "imageURL           [https://images-na.ssl-images-amazon.com/image...\n",
      "imageURLHighRes    [https://images-na.ssl-images-amazon.com/image...\n",
      "also_buy           [B000031KJT, B00000F1GS, B00002SWA8, B00000K1X...\n",
      "also_view                                   [B00000J2W7, B000PBEQ2W]\n",
      "rank               [>#31,928 in Video Games (See Top 100 in Video...\n",
      "brand                                                Acclaim Studios\n",
      "category           [Video Games, Retro Gaming & Microconsoles, Ni...\n",
      "main_cat                                                 Video Games\n",
      "tech1                                                               \n",
      "tech2                                                               \n",
      "similar_item                                                        \n",
      "date                                                                \n",
      "fit                                                                 \n",
      "Name: 945, dtype: object\n",
      "reviewerName                                1999 Amazon Shopper\n",
      "reviewerID                                       A2T532Z2TFCIIL\n",
      "registerDate                                      1404777600000\n",
      "reviewCount                                                   7\n",
      "totalVotes                                                   13\n",
      "fans                                                         84\n",
      "phoneNumber                                 (279)733-8208x31199\n",
      "homeAddress     742 Moses Islands Apt. 109, South Lee, CO 10701\n",
      "Name: 945, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# To check if the dataset is correctly loaded\n",
    "print(review_df.shape)\n",
    "print(meta_df.shape)\n",
    "print(user_df.shape)\n",
    "print(review_df.iloc[945])\n",
    "print(meta_df.iloc[945])\n",
    "print(user_df.iloc[945])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge review_df and meta_df on 'asin' to obtain price for each review\n",
    "payment_methods = ['MasterCard', 'Visa', 'PayPal', 'Discover', 'Amex', 'Bitcoin']\n",
    "\n",
    "merged_df = review_df.merge(meta_df[['asin', 'price']], on='asin', how='left')\n",
    "\n",
    "# Filter rows where price starts with '$' and convert to float\n",
    "valid_prices = merged_df['price'].str.startswith('$', na=False)\n",
    "merged_df = merged_df[valid_prices]\n",
    "merged_df['price'] = merged_df['price'].str[1:].astype(float)\n",
    "\n",
    "# Generate random copy count and calculate total price\n",
    "merged_df['copy'] = [random.randint(1, 10) for _ in range(len(merged_df))]\n",
    "merged_df['totalPrice'] = merged_df['price'] * merged_df['copy']\n",
    "\n",
    "# Compute transactionTime as a random time up to 7 days before reviewTime\n",
    "seconds_in_a_day = 86400\n",
    "random_seconds = [random.randint(0, 7 * seconds_in_a_day) for _ in range(len(merged_df))]\n",
    "review_times = pd.to_datetime(merged_df['unixReviewTime'], unit='s')\n",
    "transaction_times = review_times - pd.to_timedelta(random_seconds, unit='s')\n",
    "merged_df['transactionTime'] = transaction_times\n",
    "\n",
    "# Assign random payment method and generate unique transaction ID\n",
    "merged_df['paymentMethod'] = [random.choice(payment_methods) for _ in range(len(merged_df))]\n",
    "merged_df['transactionID'] = [str(ObjectId()) for _ in range(len(merged_df))]\n",
    "\n",
    "# Select relevant columns\n",
    "transaction_df = merged_df[['transactionID', 'transactionTime', 'asin','reviewerID', 'copy', 'totalPrice', 'paymentMethod']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"G:\\\\DSA5104 Project\\\\generated data\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "transaction_df.to_json(os.path.join(output_dir, \"transaction_data_2.json\"), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create reduced sample dataset (select 1000 unique asin's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 unique asins from meta_df\n",
    "unique_asins = meta_df['asin'].unique()\n",
    "sampled_asins = pd.Series(unique_asins).sample(n=1000, random_state=1).tolist()\n",
    "\n",
    "# Filter review_df to get reviews related to the sampled asins\n",
    "review_mask = review_df['asin'].isin(sampled_asins)\n",
    "review_data_sample = review_df[review_mask]\n",
    "\n",
    "# Get unique reviewerIDs from the filtered review_df\n",
    "unique_reviewerIDs = review_data_sample['reviewerID'].unique()\n",
    "\n",
    "# Filter user_df to get users who made the reviews\n",
    "user_mask = user_df['reviewerID'].isin(unique_reviewerIDs)\n",
    "user_data_sample = user_df[user_mask]\n",
    "\n",
    "# Filter transaction_df for sampled asins\n",
    "transaction_mask = transaction_df['asin'].isin(sampled_asins)\n",
    "transaction_data_sample = transaction_df[transaction_mask]\n",
    "\n",
    "# Filter meta_df for sampled asins\n",
    "meta_mask = meta_df['asin'].isin(sampled_asins)\n",
    "meta_data_sample = meta_df[meta_mask]\n",
    "\n",
    "# Save the reduced datasets to files\n",
    "output_dir = \"G:\\\\DSA5104 Project\\\\generated data\"\n",
    "\n",
    "meta_data_sample.to_json(os.path.join(output_dir, 'meta_data_sample.json'), orient='records', lines=True)\n",
    "review_data_sample.to_json(os.path.join(output_dir, 'review_data_sample.json'), orient='records', lines=True)\n",
    "user_data_sample.to_json(os.path.join(output_dir, 'user_data_sample.json'), orient='records', lines=True)\n",
    "transaction_data_sample.to_json(os.path.join(output_dir, 'transaction_data_sample.json'), orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
