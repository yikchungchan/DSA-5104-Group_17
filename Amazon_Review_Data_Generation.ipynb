{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for cleaning data and generating User and Transaction data based on the existed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries:\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import timedelta, datetime\n",
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the datasets\n",
    "## Change the file_path accordingly \n",
    "file_path = \"cleaning_data/review_data.json\"\n",
    "review_data = []\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "    review_data = json.load(file)\n",
    "review_df = pd.DataFrame(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"cleaning_data/meta_data.json\"\n",
    "meta_data = []\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "    meta_data = json.load(file)\n",
    "meta_df = pd.DataFrame(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6460965, 11)\n",
      "(1210967, 18)\n",
      "overall                                                         4.0\n",
      "vote                                                              1\n",
      "verified                                                      False\n",
      "reviewTime                                              08 14, 2000\n",
      "unixReviewTime                                            966211200\n",
      "reviewerID                                           A19646YDU8IH1I\n",
      "reviewerName                                    Robert Ian Farquhar\n",
      "asin                                                     B00000DMA8\n",
      "style                                     {'Edition:': ' Standard'}\n",
      "reviewText        Okay I admit it, the two main reasons I bought...\n",
      "summary                                                   Good Fun!\n",
      "Name: 945, dtype: object\n",
      "asin                                                      B00001XDVT\n",
      "title                                  Armorines: Project S.W.A.R.M.\n",
      "feature            [Great Condition, cleaned and tested, *Cartrid...\n",
      "description        [Alien bugs have swarmed to earth with a nasty...\n",
      "price                                                         $19.90\n",
      "imageURL           [https://images-na.ssl-images-amazon.com/image...\n",
      "imageURLHighRes    [https://images-na.ssl-images-amazon.com/image...\n",
      "also_buy           [B000031KJT, B00000F1GS, B00002SWA8, B00000K1X...\n",
      "also_view                                   [B00000J2W7, B000PBEQ2W]\n",
      "rank               [>#31,928 in Video Games (See Top 100 in Video...\n",
      "brand                                                Acclaim Studios\n",
      "category           [Video Games, Retro Gaming & Microconsoles, Ni...\n",
      "main_cat                                                 Video Games\n",
      "tech1                                                               \n",
      "tech2                                                               \n",
      "similar_item                                                        \n",
      "date                                                                \n",
      "fit                                                                 \n",
      "Name: 945, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# To check if the dataset is correctly loaded\n",
    "print(review_df.shape)\n",
    "print(meta_df.shape)\n",
    "print(review_df.iloc[945])\n",
    "print(meta_df.iloc[945])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.shape\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in review_df:\n",
      "overall                 0\n",
      "vote                    0\n",
      "verified                0\n",
      "reviewTime              0\n",
      "unixReviewTime          0\n",
      "reviewerID              0\n",
      "reviewerName            0\n",
      "asin                    0\n",
      "style             1521260\n",
      "reviewText              0\n",
      "summary                 0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in meta_df:\n",
      "asin               0\n",
      "title              0\n",
      "feature            0\n",
      "description        0\n",
      "price              0\n",
      "imageURL           0\n",
      "imageURLHighRes    0\n",
      "also_buy           0\n",
      "also_view          0\n",
      "rank               0\n",
      "brand              0\n",
      "category           0\n",
      "main_cat           0\n",
      "tech1              0\n",
      "tech2              0\n",
      "similar_item       0\n",
      "date               0\n",
      "fit                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Check the NULL values inside datasets\n",
    "# Checking for missing values\n",
    "print(\"\\nMissing values in review_df:\")\n",
    "print(review_df.isnull().sum()) # have missing values in \"style\"\n",
    "\n",
    "print(\"\\nMissing values in meta_df:\")\n",
    "print(meta_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When checking the dataset, I found some elements in \"price\" column is bad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<span class=\"verticalAlign a-size-large\"'\n",
      " '$0.72' ... '$217.06' '$108.49' '$293.99']\n",
      "Number of elements with an empty string in 'price': 658678\n",
      "Number of elements not in the form '$[some number]' in 'price': 770753\n"
     ]
    }
   ],
   "source": [
    "unique_prices_with_nan = meta_df['price'].unique()\n",
    "print(unique_prices_with_nan) # many price is ''\n",
    "\n",
    "# Count of elements with an empty string in \"price\"\n",
    "empty_string_count = meta_df[meta_df['price'] == \"\"].shape[0]\n",
    "\n",
    "pattern = r'^\\$\\d+(\\.\\d{1,2})?$'\n",
    "non_matching_count = meta_df[~meta_df['price'].str.match(pattern, na=False)].shape[0]\n",
    "\n",
    "print(f\"Number of elements with an empty string in 'price': {empty_string_count}\")\n",
    "print(f\"Number of elements not in the form '$[some number]' in 'price': {non_matching_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the codes for cleaning the \"price\" element (generate some fake prices for these \"bad\" elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a random price in the format $x.xx\n",
    "def generate_random_price():\n",
    "    # Generate a random float between 0.01 and 299.99\n",
    "    random_price = round(random.uniform(0.01, 299.99), 2)\n",
    "    # Convert to string format with 2 decimal places and prepend with a dollar sign\n",
    "    return f\"${random_price:.2f}\"\n",
    "\n",
    "# Identify the indices of rows that have an empty string or not in the desired format in the 'price' column\n",
    "pattern = r'^\\$\\d+(\\.\\d{1,2})?$'\n",
    "invalid_price_indices = meta_df[~meta_df['price'].str.match(pattern, na=False)].index\n",
    "\n",
    "# Replace these values with randomly generated prices\n",
    "meta_df.loc[invalid_price_indices, 'price'] = meta_df.loc[invalid_price_indices, 'price'].apply(lambda x: generate_random_price())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements with an empty string in 'price': 0\n",
      "Number of elements not in the form '$[some number]' in 'price': 0\n"
     ]
    }
   ],
   "source": [
    "# Check again\n",
    "empty_string_count = meta_df[meta_df['price'] == \"\"].shape[0]\n",
    "\n",
    "pattern = r'^\\$\\d+(\\.\\d{1,2})?$'\n",
    "non_matching_count = meta_df[~meta_df['price'].str.match(pattern, na=False)].shape[0]\n",
    "\n",
    "print(f\"Number of elements with an empty string in 'price': {empty_string_count}\")\n",
    "print(f\"Number of elements not in the form '$[some number]' in 'price': {non_matching_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, let's generate some User data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we observe that there are two columns \"reviewerName\" and \"reviewerID\". We do some checking on these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique reviewerNames: 460580\n",
      "Number of unique reviewerIDs: 641085\n"
     ]
    }
   ],
   "source": [
    "unique_reviewerNames = review_df['reviewerName'].unique()\n",
    "unique_reviewerIDs = review_df['reviewerID'].unique()\n",
    "\n",
    "# Print the number of unique values for each\n",
    "print(f\"Number of unique reviewerNames: {len(unique_reviewerNames)}\")\n",
    "print(f\"Number of unique reviewerIDs: {len(unique_reviewerIDs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent reviewerName: Amazon Customer\n",
      "Most frequent reviewerID: AV6QDP8Q0ONK4\n"
     ]
    }
   ],
   "source": [
    "most_frequent_reviewerName = review_df['reviewerName'].mode().iloc[0]\n",
    "most_frequent_reviewerID = review_df['reviewerID'].mode().iloc[0]\n",
    "\n",
    "print(f\"Most frequent reviewerName: {most_frequent_reviewerName}\")\n",
    "print(f\"Most frequent reviewerID: {most_frequent_reviewerID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with both \"reviewerName\" and \"reviewerID\" present:\n",
    "both_present_df = review_df[(review_df['reviewerName'] != \"\") & (review_df['reviewerID'] != \"\")]\n",
    "\n",
    "# Rows with only \"reviewerName\" present:\n",
    "only_name_df = review_df[(review_df['reviewerName'] != \"\") & (review_df['reviewerID'] == \"\")]\n",
    "\n",
    "# Rows with only \"reviewerID\" present:\n",
    "only_id_df = review_df[(review_df['reviewerName'] == \"\") & (review_df['reviewerID'] != \"\")]\n",
    "\n",
    "# Rows where both \"reviewerName\" and \"reviewerID\" are missing:\n",
    "both_missing_df = review_df[(review_df['reviewerName'] == \"\") & (review_df['reviewerID'] == \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with both reviewerName and reviewerID present: 6460965\n",
      "Rows with only reviewerName present: 0\n",
      "Rows with only reviewerID present: 0\n",
      "Rows where both reviewerName and reviewerID are missing: 0\n"
     ]
    }
   ],
   "source": [
    "# To get the count of rows for each condition\n",
    "print(\"Rows with both reviewerName and reviewerID present:\", both_present_df.shape[0])\n",
    "print(\"Rows with only reviewerName present:\", only_name_df.shape[0])\n",
    "print(\"Rows with only reviewerID present:\", only_id_df.shape[0])\n",
    "print(\"Rows where both reviewerName and reviewerID are missing:\", both_missing_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5825 reviewer names longer than 40 characters.\n"
     ]
    }
   ],
   "source": [
    "long_names = len(review_df[review_df['reviewerName'].str.len() > 40]['reviewerName'])\n",
    "\n",
    "print(f'There are {long_names} reviewer names longer than 40 characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace long reviewer names with fake names\n",
    "fake = Faker()\n",
    "\n",
    "def replace_long_name(name):\n",
    "    if len(name) > 40:\n",
    "        return fake.first_name()\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "# Apply the function to the reviewerName column of review_df\n",
    "review_df['reviewerName'] = review_df['reviewerName'].apply(replace_long_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 reviewer IDs longer than 20 characters.\n"
     ]
    }
   ],
   "source": [
    "long_ids = len(review_df[review_df['reviewerID'].str.len() > 20]['reviewerName'])\n",
    "\n",
    "print(f'There are {long_ids} reviewer IDs longer than 20 characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 reviewer names longer than 40 characters.\n"
     ]
    }
   ],
   "source": [
    "# Check again\n",
    "long_names = len(review_df[review_df['reviewerName'].str.len() > 40]['reviewerName'])\n",
    "\n",
    "print(f'There are {long_names} reviewer names longer than 40 characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use these information to generate User data (Here I use Yelp User data as an example)\n",
    "\n",
    "**Some explanations for the User Data**:\n",
    "\n",
    "**reviewerName and reviewerID**: Referencing the review column (for each unique reviewerName and reviewerID pair, generate one user record)\n",
    "\n",
    "**registerDate**: Timestamp of user's registeration date and time\n",
    "\n",
    "**reviewCount**: how many review does the user posted (checking the number of records in \"review_df\")\n",
    "\n",
    "**totalVotes**: Total votes the user get for his reviews (also checking \"vote\" in \"review_df\")\n",
    "\n",
    "**fans**: Fake fans number of the user (For user with higher total votes, his fans number should be higher)\n",
    "\n",
    "**phoneNumber**: Fake phone number of the user\n",
    "\n",
    "**homeAddress**: Fake home address of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "review_df['vote'] = pd.to_numeric(review_df['vote'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "review_df['vote'].fillna(0, inplace=True)\n",
    "\n",
    "# Group by reviewerName and reviewerID, and aggregate needed information\n",
    "user_df = review_df.groupby(['reviewerName', 'reviewerID']).agg(\n",
    "    registerDate=pd.NamedAgg(column='unixReviewTime', aggfunc='min'),\n",
    "    reviewCount=pd.NamedAgg(column='asin', aggfunc='size'),\n",
    "    totalVotes=pd.NamedAgg(column='vote', aggfunc='sum')\n",
    ").reset_index()\n",
    "\n",
    "# Convert registerDate from UNIX timestamp to datetime format\n",
    "user_df['registerDate'] = pd.to_datetime(user_df['registerDate'], unit='s')\n",
    "\n",
    "# Subtract a random number of days (between 1 and 365) from the earliest review date\n",
    "user_df['registerDate'] = user_df['registerDate'] - pd.to_timedelta(np.random.randint(1, 365, size=len(user_df)), unit='D')\n",
    "\n",
    "# Generate fake fans number based on totalVotes\n",
    "user_df['fans'] = (np.log(user_df['totalVotes'] + 1) * 30).astype(int) + 5\n",
    "\n",
    "# Generate fake phone number and home address for each user\n",
    "user_df['phoneNumber'] = user_df['reviewerName'].apply(lambda x: fake.phone_number())\n",
    "user_df['homeAddress'] = user_df['reviewerName'].apply(lambda x: fake.address().replace('\\n', ', '))\n",
    "\n",
    "user_df = user_df[['reviewerName', 'reviewerID', 'registerDate', 'reviewCount', 'totalVotes', 'fans', 'phoneNumber', 'homeAddress']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658400, 8)\n",
      "reviewerName                              SHAMROCK FPV Chucks P. \n",
      "reviewerID                                         A1ZXRG90P7WHB2\n",
      "registerDate                                  2013-08-31 00:00:00\n",
      "reviewCount                                                     6\n",
      "totalVotes                                                    6.0\n",
      "fans                                                           63\n",
      "phoneNumber                                001-721-658-3048x31780\n",
      "homeAddress     434 Wilkinson Courts Suite 488, Port Raymond, ...\n",
      "Name: 65, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the generated user data\n",
    "print(user_df.shape)\n",
    "print(user_df.iloc[65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's generate the transaction records:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explanations for the generated transaction records:\n",
    "\n",
    "**transactionID**: an unique id for each transaction \n",
    "\n",
    "**transactionTime**: Simulated transaction time, a little bit earlier than the review time (0-3 days)\n",
    "\n",
    "**buyerID**: The ID of the buyer (also the reviewer, referencing the reviewerID)\n",
    "\n",
    "**copy**: how many copies the buyer bought. randomly chosen from 1-10\n",
    "\n",
    "**totalPrice**: calculated total price (price * copy)\n",
    "\n",
    "**paymentMethod**: fake payment method (master card, paypal etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\DSA5104 Project\\Amazon_Review_Data_Generation.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/DSA5104%20Project/Amazon_Review_Data_Generation.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reviewerID \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mreviewerID\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/DSA5104%20Project/Amazon_Review_Data_Generation.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Extract price for the corresponding product from meta_df\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/DSA5104%20Project/Amazon_Review_Data_Generation.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m item_price \u001b[39m=\u001b[39m meta_df[meta_df[\u001b[39m'\u001b[39;49m\u001b[39masin\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m asin][\u001b[39m'\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/DSA5104%20Project/Amazon_Review_Data_Generation.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# If the price is missing or not in correct format, skip this row (or you can assign a default price)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/DSA5104%20Project/Amazon_Review_Data_Generation.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m item_price\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m$\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mg:\\Python 3.11\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mg:\\Python 3.11\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[1;32mg:\\Python 3.11\\Lib\\site-packages\\pandas\\core\\series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6093\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   6095\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 6096\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6098\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mg:\\Python 3.11\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    292\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mg:\\Python 3.11\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:83\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mscalar_compare(x\u001b[39m.\u001b[39mravel(), y, op)\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39;49mreshape(x\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This version is time-consuming\n",
    "# Initialize the list of possible payment methods\n",
    "payment_methods = ['MasterCard', 'Visa', 'PayPal', 'Discover', 'Amex', 'Bitcoin']\n",
    "\n",
    "# For each review, generate a transaction record\n",
    "transactions = []\n",
    "\n",
    "for index, row in review_df.iterrows():\n",
    "    asin = row['asin']\n",
    "    reviewerID = row['reviewerID']\n",
    "    \n",
    "    # Extract price for the corresponding product from meta_df\n",
    "    item_price = meta_df[meta_df['asin'] == asin]['price'].iloc[0]\n",
    "    \n",
    "    # If the price is missing or not in correct format, skip this row (or you can assign a default price)\n",
    "    if not item_price.startswith('$'):\n",
    "        continue\n",
    "    item_price = float(item_price[1:])  # Convert price from string to float, excluding the dollar sign\n",
    "    \n",
    "    # Determine copy and calculate total price\n",
    "    copy_count = random.randint(1, 10)\n",
    "    total_price = item_price * copy_count\n",
    "    \n",
    "    # Determine the transaction time\n",
    "    review_time = pd.to_datetime(row['unixReviewTime'], unit='s')\n",
    "    seconds_in_a_day = 86400\n",
    "    random_seconds = random.randint(0, 7 * seconds_in_a_day)\n",
    "    transaction_time = review_time - timedelta(seconds=random_seconds)\n",
    "    \n",
    "    # Append the transaction record to the list\n",
    "    transactions.append({\n",
    "        'transactionID': str(ObjectId()),\n",
    "        'transactionTime': transaction_time,\n",
    "        'buyerID': reviewerID,\n",
    "        'copy': copy_count,\n",
    "        'totalPrice': total_price,\n",
    "        'paymentMethod': random.choice(payment_methods)\n",
    "    })\n",
    "\n",
    "# Convert the list of transactions into a DataFrame\n",
    "transaction_df = pd.DataFrame(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this version\n",
    "# Merge review_df and meta_df on 'asin' to obtain price for each review\n",
    "payment_methods = ['MasterCard', 'Visa', 'PayPal', 'Discover', 'Amex', 'Bitcoin']\n",
    "\n",
    "merged_df = review_df.merge(meta_df[['asin', 'price']], on='asin', how='left')\n",
    "\n",
    "# Filter rows where price starts with '$' and convert to float\n",
    "valid_prices = merged_df['price'].str.startswith('$', na=False)\n",
    "merged_df = merged_df[valid_prices]\n",
    "merged_df['price'] = merged_df['price'].str[1:].astype(float)\n",
    "\n",
    "# Generate random copy count and calculate total price\n",
    "merged_df['copy'] = [random.randint(1, 10) for _ in range(len(merged_df))]\n",
    "merged_df['totalPrice'] = merged_df['price'] * merged_df['copy']\n",
    "\n",
    "# Compute transactionTime as a random time up to 7 days before reviewTime\n",
    "seconds_in_a_day = 86400\n",
    "random_seconds = [random.randint(0, 7 * seconds_in_a_day) for _ in range(len(merged_df))]\n",
    "review_times = pd.to_datetime(merged_df['unixReviewTime'], unit='s')\n",
    "transaction_times = review_times - pd.to_timedelta(random_seconds, unit='s')\n",
    "merged_df['transactionTime'] = transaction_times\n",
    "\n",
    "# Assign random payment method and generate unique transaction ID\n",
    "merged_df['paymentMethod'] = [random.choice(payment_methods) for _ in range(len(merged_df))]\n",
    "merged_df['transactionID'] = [str(ObjectId()) for _ in range(len(merged_df))]\n",
    "\n",
    "# Select relevant columns\n",
    "transaction_df = merged_df[['transactionID', 'transactionTime', 'reviewerID', 'copy', 'totalPrice', 'paymentMethod']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6453130, 6)\n",
      "transactionID      65394be6e6e35c3b983f529a\n",
      "transactionTime         2010-09-08 10:16:57\n",
      "reviewerID                   A1FDNRZT2G0LGD\n",
      "copy                                      1\n",
      "totalPrice                            31.16\n",
      "paymentMethod                    MasterCard\n",
      "Name: 625, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the generated user data\n",
    "print(transaction_df.shape)\n",
    "print(transaction_df.iloc[625])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the new data into four JSON files to folder called \"generated data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a new folder called \"generated data\"\n",
    "output_dir = \"G:\\\\DSA5104 Project\\\\generated data\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the dataframes into JSON files\n",
    "meta_df.to_json(os.path.join(output_dir, \"meta_data.json\"), orient='records', lines=True)\n",
    "review_df.to_json(os.path.join(output_dir, \"review_data.json\"), orient='records', lines=True)\n",
    "user_df.to_json(os.path.join(output_dir, \"user_data.json\"), orient='records', lines=True)\n",
    "transaction_df.to_json(os.path.join(output_dir, \"transaction_data.json\"), orient='records', lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
